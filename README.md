# Bose Gesture Library for iOS

Provides BoseWearable SDK developers with tools capable of interpreting raw IMU sensor data as meaningful, higher-level constructs. Natural human movements create easy interactions for Bose AR apps to interpret when leveraging the Gestures library. Examples include head nod, head shake, look left, look right, and more.

## System Requirements

Use of the Bose Gesture Library requires the following:

- Xcode 11.0 or later
- Swift 5
- iOS 12.0 or later

## Getting Started

This repo contains the Bose Gesture Library for iOS as well as an example app. See [Sample Code](docs/Sample%20Code.md) for instructions on how to build and run the example.

## Installation

See the [Installation Guide](docs/Installation.md) for instructions on how to integrate the Bose Gesture Library with your app.

## Usage

See the [Usage Guide](docs/Usage.md) for detailed information about how to use the Bose Gesture Library in your app.

## Documentation

Visit [BoseGesture Reference](https://bosecorp.github.io/BoseWearable-GestureLib-iOS-bin/index.html) for complete documentation. 
